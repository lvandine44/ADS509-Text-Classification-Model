{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes on Political Text\n",
    "\n",
    "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details. You can download the required DB from the shared dropbox or from blackboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import nltk\n",
    "import string\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "from string import punctuation\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Define stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Feel free to include your text patterns functions\n",
    "#from text_functions_solutions import clean_tokenize, get_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_db = sqlite3.connect(\"2020_Conventions.db\")\n",
    "convention_cur = convention_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in table 'conventions':\n",
      " - party (Type: TEXT)\n",
      " - night (Type: INTEGER)\n",
      " - speaker (Type: TEXT)\n",
      " - speaker_count (Type: INTEGER)\n",
      " - time (Type: TEXT)\n",
      " - text (Type: TEXT)\n",
      " - text_len (Type: TEXT)\n",
      " - file (Type: TEXT)\n"
     ]
    }
   ],
   "source": [
    "# Check the database for tables and column names to use later on\n",
    "# Get the list of tables in the database\n",
    "try:\n",
    "    tables = convention_cur.execute(\"SELECT name FROM sqlite_master WHERE type='table';\").fetchall()\n",
    "    \n",
    "    if not tables:\n",
    "        print(\"No tables found in the database.\")\n",
    "    else:\n",
    "        # Step 2: Print columns for each table\n",
    "        for table_name in tables:\n",
    "            table_name = table_name[0]  # Extract the table name from the tuple\n",
    "            print(f\"Columns in table '{table_name}':\")\n",
    "            \n",
    "            # Execute PRAGMA command to get column info\n",
    "            columns = convention_cur.execute(f\"PRAGMA table_info({table_name});\").fetchall()\n",
    "            \n",
    "            if not columns:\n",
    "                print(f\"No columns found in table '{table_name}'.\")\n",
    "            else:\n",
    "                for column in columns:\n",
    "                    print(f\" - {column[1]} (Type: {column[2]})\")  # Column name and type\n",
    "\n",
    "except sqlite3.Error as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records in conventions table: 2541\n",
      "Sample records from the conventions table:\n",
      "('Democratic', 4, 'Unknown', 1, '00:00', 'Skip to content The Company Careers Press Freelancers Blog × Services Transcription Captions Foreign Subtitles Translation Freelancers About Contact Login « Return to Transcript Library home  Transcript Categories  All Transcripts 2020 Election Transcripts Classic Speech Transcripts Congressional Testimony & Hearing Transcripts Debate Transcripts Donald Trump Transcripts Entertainment Transcripts Financial Transcripts Interview Transcripts Political Transcripts Press Conference Transcripts Speech Transcripts Sports Transcripts Technology Transcripts Aug 21, 2020 2020 Democratic National Convention (DNC) Night 4 Transcript Rev  ›  Blog  ›  Transcripts  › 2020 Election Transcripts  ›  2020 Democratic National Convention (DNC) Night 4 Transcript Night 4 of the 2020 Democratic National Convention (DNC) on August 20. Read the full transcript of the event here. Transcribe Your Own Content  Try Rev for free  and save time transcribing, captioning, and subtitling.', '127', 'www_rev_com_blog_transcripts2020-democratic-national-convention-dnc-night-4-transcript.txt')\n",
      "('Democratic', 4, 'Speaker 1', 1, '00:33', 'I’m here by calling the full session of the 48th Quadrennial National Convention of the Democratic Party to order. Welcome all to our final session of this historic and memorable convention. We’ve called the 48th Quadrennial Democratic National Convention to order.', '41', 'www_rev_com_blog_transcripts2020-democratic-national-convention-dnc-night-4-transcript.txt')\n",
      "('Democratic', 4, 'Speaker 2', 1, '00:59', 'Every four years, we come together to reaffirm our democracy. This year, we’ve come to save it.', '17', 'www_rev_com_blog_transcripts2020-democratic-national-convention-dnc-night-4-transcript.txt')\n",
      "('Democratic', 4, 'Kerry Washington', 1, '01:07', 'We fight for a more perfect union because we are fighting for the soul of this country and for our lives. And right now that fight is real.', '28', 'www_rev_com_blog_transcripts2020-democratic-national-convention-dnc-night-4-transcript.txt')\n",
      "('Democratic', 4, 'Bernie Sanders', 1, '01:18', 'We must come together to defeat Donald Trump, and elect Joe Biden and Kamala Harris as our next President and Vice President.', '22', 'www_rev_com_blog_transcripts2020-democratic-national-convention-dnc-night-4-transcript.txt')\n"
     ]
    }
   ],
   "source": [
    "# Validate the data from 2020_Conventions database\n",
    "# Fetch all records to inspect the data\n",
    "all_data = convention_cur.execute(\"SELECT * FROM conventions\").fetchall()\n",
    "\n",
    "# Print the number of records and some sample data\n",
    "print(f\"Total records in conventions table: {len(all_data)}\")\n",
    "print(\"Sample records from the conventions table:\")\n",
    "for record in all_data[:5]:  # Print first 5 records for inspection\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" exercise. First, we'll pull in the text \n",
    "for each party and prepare it for use in Naive Bayes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample convention_data entries: [['Skip to content The Company Careers Press Freelancers Blog × Services Transcription Captions Foreign Subtitles Translation Freelancers About Contact Login « Return to Transcript Library home  Transcript Categories  All Transcripts 2020 Election Transcripts Classic Speech Transcripts Congressional Testimony & Hearing Transcripts Debate Transcripts Donald Trump Transcripts Entertainment Transcripts Financial Transcripts Interview Transcripts Political Transcripts Press Conference Transcripts Speech Transcripts Sports Transcripts Technology Transcripts Aug 21, 2020 2020 Democratic National Convention (DNC) Night 4 Transcript Rev  ›  Blog  ›  Transcripts  › 2020 Election Transcripts  ›  2020 Democratic National Convention (DNC) Night 4 Transcript Night 4 of the 2020 Democratic National Convention (DNC) on August 20. Read the full transcript of the event here. Transcribe Your Own Content  Try Rev for free  and save time transcribing, captioning, and subtitling.', 'Democratic'], ['I’m here by calling the full session of the 48th Quadrennial National Convention of the Democratic Party to order. Welcome all to our final session of this historic and memorable convention. We’ve called the 48th Quadrennial Democratic National Convention to order.', 'Democratic'], ['Every four years, we come together to reaffirm our democracy. This year, we’ve come to save it.', 'Democratic'], ['We fight for a more perfect union because we are fighting for the soul of this country and for our lives. And right now that fight is real.', 'Democratic'], ['We must come together to defeat Donald Trump, and elect Joe Biden and Kamala Harris as our next President and Vice President.', 'Democratic']]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the convention_data list\n",
    "convention_data = []\n",
    "\n",
    "# SQL query to pull only 2020 data and exclude the \"Other\" party\n",
    "query_results = convention_cur.execute(\n",
    "    '''\n",
    "    SELECT text, party \n",
    "    FROM conventions \n",
    "    WHERE party != 'Other'\n",
    "    '''\n",
    ")\n",
    "\n",
    "# Store the results in convention_data\n",
    "for row in query_results:\n",
    "    speech_text, party = row  # Unpack the row into speech_text and party\n",
    "    convention_data.append([speech_text, party])  # Add to the list as a sublist\n",
    "\n",
    "# Optional: Print the first few entries to verify\n",
    "print(f\"Sample convention_data entries: {convention_data[:5]}\")\n",
    "\n",
    "# Close the database connection\n",
    "convention_cur.close()\n",
    "convention_db.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Today I’m proud to join Joe Biden.', 'Democratic'],\n",
       " ['Illinois.', 'Republican'],\n",
       " ['[foreign language 00:32:04].', 'Democratic'],\n",
       " ['Democracy is beautiful.', 'Democratic'],\n",
       " ['Welcome back to Milwaukee, Wisconsin, a great city on native land on a Great Lake. It’s the place where I was born and raised right in the heart of 53206 zip code. This is a community that’s been faced with some significant challenges due to historical injustice, but what many don’t see is the joy, the resilience, and opportunity that lies within this community and so many others across America just like it, where hardworking people are fighting to provide for their families and to build a better future. We know that we build a better future for our nation by channeling Wisconsin’s legacy as the birthplace of the labor and the progressive movement, and uniting around a bold inclusive agenda that uplifts every community and the pursuit of a more just future, one that recognizes healthcare as a human right, one that tackles the climate crisis and takes on racial and economic justice. Wisconsin cast 30 votes for Bernie Sanders and 67 for the next President of the United States of America, Joseph R. Biden.',\n",
       "  'Democratic']]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(convention_data,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It'll be useful for us to have a large sample size than 2020 affords, since those speeches tend to be long and contiguous. Let's make a new list-of-lists called `conv_sent_data`. Instead of each first entry in the sublists being an entire speech, make each first entry just a sentence from the speech. Feel free to use NLTK's `sent_tokenize` [function](https://www.nltk.org/api/nltk.tokenize.sent_tokenize.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_sent_data = []\n",
    "\n",
    "# Iterate over each speech and party in original list convention_data\n",
    "for speech, party in convention_data:\n",
    "    # Tokenize the speech into sentences\n",
    "    sentences = sent_tokenize(speech)\n",
    "    \n",
    "    # Append each sentence and the corresponding party to new conv_sent_data\n",
    "    for sentence in sentences:\n",
    "        conv_sent_data.append([sentence, party])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's look at some random entries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Our platoon reflected the diversity of our nation, every race, creed, and religion.',\n",
       "  'Republican'],\n",
       " ['God bless our heroes and God bless the United States of America.',\n",
       "  'Republican'],\n",
       " ['We are idealists and dreamers, lovers of adventure.', 'Republican'],\n",
       " ['Believe in yourself, in President Trump and individual and personal responsibility?',\n",
       "  'Republican'],\n",
       " ['We want safety in our neighborhoods.', 'Republican']]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(conv_sent_data,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time for our final cleaning before modeling. Go through `conv_sent_data` and take the following steps: \n",
    "\n",
    "1. Tokenize on whitespace\n",
    "1. Remove punctuation\n",
    "1. Remove tokens that fail the `isalpha` test\n",
    "1. Remove stopwords\n",
    "1. Casefold to lowercase\n",
    "1. Join the remaining tokens into a string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('maybe one day catch', 'Republican'),\n",
       " ('change within change made last', 'Republican'),\n",
       " ('whoo', 'Republican'),\n",
       " ('want talk man know', 'Republican'),\n",
       " ('lucky', 'Republican')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clean_conv_sent_data = [] # list of tuples (sentence, party), with sentence cleaned\n",
    "\n",
    "for idx, sent_party in enumerate(conv_sent_data) :\n",
    "    pass # your code here\n",
    "\n",
    "random.choices(clean_conv_sent_data,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_conv_sent_data = []  # list of tuples (sentence, party), with sentence cleaned\n",
    "\n",
    "# Iterate over each sentence and party in conv_sent_data\n",
    "for idx, (sentence, party) in enumerate(conv_sent_data):\n",
    "    # Tokenize on whitespace\n",
    "    tokens = word_tokenize(sentence)\n",
    "\n",
    "    # Remove punctuation and isalpha tokens\n",
    "    tokens = [\n",
    "        token for token in tokens\n",
    "        if token.isalpha() and token.lower() not in stop_words\n",
    "    ]\n",
    "\n",
    "    # Lowercase\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "\n",
    "    # Join the remaining tokens into a string\n",
    "    cleaned_sentence = ' '.join(tokens)\n",
    "\n",
    "    # Store the cleaned sentence and the party in clean_conv_sent_data\n",
    "    clean_conv_sent_data.append((cleaned_sentence, party))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('good evening', 'Democratic'), ('want thank much', 'Republican'), ('know alive today', 'Republican'), ('one first people called joe', 'Democratic'), ('ready', 'Democratic')]\n"
     ]
    }
   ],
   "source": [
    "# Example to show random samples from the cleaned data (data check)\n",
    "random_samples = random.choices(clean_conv_sent_data, k=5)\n",
    "print(random_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks good, let's make our function to turn these into features. First we need to build our list of candidate words. I started my exploration at a cutoff of 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 2236 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "word_cutoff = 5\n",
    "\n",
    "# Flatten the cleaned sentences into a list of words\n",
    "tokens = [w for t, p in clean_conv_sent_data for w in t.split()]\n",
    "\n",
    "# Calculate the frequency distribution of words\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "# Build the set of feature words based on the cutoff\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items():\n",
    "    if count > word_cutoff:\n",
    "        feature_words.add(word)\n",
    "\n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text, fw):\n",
    "    \"\"\"Given some text, this returns a dictionary holding the\n",
    "       feature words.\n",
    "       \n",
    "       Args: \n",
    "            * text: a piece of text in a continuous string. Assumes\n",
    "            text has been cleaned and case folded.\n",
    "            * fw: the *feature words* that we're considering. A word \n",
    "            in `text` must be in fw in order to be returned. This \n",
    "            prevents us from considering very rarely occurring words.\n",
    "        \n",
    "       Returns: \n",
    "            A dictionary with the words in `text` that appear in `fw`. \n",
    "            Words are only counted once.\n",
    "            If `text` were \"quick quick brown fox\" and `fw` = {'quick','fox','jumps'},\n",
    "            then this would return a dictionary of \n",
    "            {'quick' : True,\n",
    "             'fox' :    True}\n",
    "    \"\"\"\n",
    "    # Tokenize the text into words\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # Create the dictionary for feature words found in the text\n",
    "    ret_dict = {word: True for word in tokens if word in fw}\n",
    "    \n",
    "    return ret_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assertions to test the function\n",
    "assert(len(feature_words) > 0)\n",
    "assert(conv_features(\"obama was the president\", feature_words) == {'obama': True, 'president': True})\n",
    "assert(conv_features(\"some people in america are citizens\", feature_words) == {'people': True, 'america': True, 'citizens': True})\n",
    "\n",
    "# will pass silently if all assertions run correctly, otherwise assertion error will occur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(conv_features(text,feature_words), party) for (text, party) in convention_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220507)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.498\n"
     ]
    }
   ],
   "source": [
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             enforcement = True           Republ : Democr =     27.5 : 1.0\n",
      "                   votes = True           Democr : Republ =     21.6 : 1.0\n",
      "                 climate = True           Democr : Republ =     17.3 : 1.0\n",
      "                 destroy = True           Republ : Democr =     17.1 : 1.0\n",
      "                supports = True           Republ : Democr =     16.1 : 1.0\n",
      "                   media = True           Republ : Democr =     15.9 : 1.0\n",
      "                preserve = True           Republ : Democr =     15.1 : 1.0\n",
      "                  signed = True           Republ : Democr =     15.1 : 1.0\n",
      "              appreciate = True           Republ : Democr =     14.0 : 1.0\n",
      "                freedoms = True           Republ : Democr =     14.0 : 1.0\n",
      "                 private = True           Republ : Democr =     11.9 : 1.0\n",
      "                  defund = True           Republ : Democr =     10.9 : 1.0\n",
      "                    drug = True           Republ : Democr =     10.3 : 1.0\n",
      "                 special = True           Republ : Democr =     10.3 : 1.0\n",
      "                   trade = True           Republ : Democr =     10.0 : 1.0\n",
      "                everyday = True           Republ : Democr =      9.9 : 1.0\n",
      "                   local = True           Republ : Democr =      9.9 : 1.0\n",
      "                 allowed = True           Republ : Democr =      9.7 : 1.0\n",
      "                   elect = True           Democr : Republ =      9.6 : 1.0\n",
      "                   moved = True           Republ : Democr =      9.0 : 1.0\n",
      "                   bless = True           Republ : Democr =      9.0 : 1.0\n",
      "                    land = True           Republ : Democr =      8.9 : 1.0\n",
      "                  agenda = True           Republ : Democr =      8.8 : 1.0\n",
      "               countries = True           Republ : Democr =      8.8 : 1.0\n",
      "                   crime = True           Republ : Democr =      8.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a little prose here about what you see in the classifier. Anything odd or interesting?\n",
    "\n",
    "### My Observations\n",
    "\n",
    "It is important to note that the accuracy of the Naive Bayes classifier is less than 0.50, 50%. Many of the important features posted by the Naive Bayes classifier are expected when analyzing a political environment. It is interesting to see the specific features that are notoriously stronger in the Republican party versus the Democratic party actually be proven by text. For example, the Republican party sees the largest ratio with \"enforcement\" which coincides with the strong presence of militant priorities, etc. In contrast, the Democratic party has a high ratio for features such as \"climate\", which coincides with priorities of social change and environmental issues. \n",
    "\n",
    "It is also intriguing to look at how many features are marked as significantly occuring for each party. Out of the 25 of the features listed here, 22 of them appear to occur more frequently in the Republican party speeches. This could suggest potential bias in the collection of data, or just an imbalance in the data as is. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
    "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
    "give you the query I used to pull out the tweets. Note that this DB has some big tables and \n",
    "is unindexed, so the query takes a minute or two to run on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_db = sqlite3.connect(\"congressional_data.db\")\n",
    "cong_cur = cong_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cong_cur.execute(\n",
    "        '''\n",
    "           SELECT DISTINCT \n",
    "                  cd.candidate, \n",
    "                  cd.party,\n",
    "                  tw.tweet_text\n",
    "           FROM candidate_data cd \n",
    "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
    "               AND cd.candidate == tw.candidate \n",
    "               AND cd.district == tw.district\n",
    "           WHERE cd.party in ('Republican','Democratic') \n",
    "               AND tw.tweet_text NOT LIKE '%RT%'\n",
    "        ''')\n",
    "\n",
    "results = list(results) # Just to store it, since the query is time consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in table 'websites':\n",
      " - district (Type: TEXT)\n",
      " - candidate (Type: TEXT)\n",
      " - pull_time (Type: DATETIME)\n",
      " - url (Type: TEXT)\n",
      " - site_text (Type: TEXT)\n",
      "Columns in table 'candidate_data':\n",
      " - index (Type: INTEGER)\n",
      " - student (Type: TEXT)\n",
      " - state (Type: TEXT)\n",
      " - district_num (Type: TEXT)\n",
      " - formatted_dist_num (Type: INTEGER)\n",
      " - abbrev (Type: TEXT)\n",
      " - district (Type: TEXT)\n",
      " - candidate (Type: TEXT)\n",
      " - party (Type: TEXT)\n",
      " - website (Type: TEXT)\n",
      " - twitter_handle (Type: TEXT)\n",
      " - incumbent (Type: TEXT)\n",
      " - age (Type: REAL)\n",
      " - gender (Type: TEXT)\n",
      " - marital_status (Type: TEXT)\n",
      " - white_non_hispanic (Type: TEXT)\n",
      " - hispanic (Type: TEXT)\n",
      " - black (Type: TEXT)\n",
      " - partisian_lean_pvi (Type: TEXT)\n",
      " - opposed (Type: TEXT)\n",
      " - pct_urban (Type: TEXT)\n",
      " - income (Type: REAL)\n",
      " - region (Type: TEXT)\n",
      "Columns in table 'tweets':\n",
      " - district (Type: TEXT)\n",
      " - candidate (Type: TEXT)\n",
      " - pull_time (Type: DATETIME)\n",
      " - tweet_time (Type: DATETIME)\n",
      " - handle (Type: TEXT)\n",
      " - is_retweet (Type: INTEGER)\n",
      " - tweet_id (Type: TEXT)\n",
      " - tweet_text (Type: TEXT)\n",
      " - likes (Type: INTEGER)\n",
      " - replies (Type: INTEGER)\n",
      " - retweets (Type: INTEGER)\n",
      " - tweet_ratio (Type: REAL)\n"
     ]
    }
   ],
   "source": [
    "# Check the database for tables and column names\n",
    "try:\n",
    "    # Step 1: Get the list of tables in the database\n",
    "    tables = cong_cur.execute(\"SELECT name FROM sqlite_master WHERE type='table';\").fetchall()\n",
    "    \n",
    "    if not tables:\n",
    "        print(\"No tables found in the database.\")\n",
    "    else:\n",
    "        # Step 2: Print columns for each table\n",
    "        for table_name in tables:\n",
    "            table_name = table_name[0]  # Extract the table name from the tuple\n",
    "            print(f\"Columns in table '{table_name}':\")\n",
    "            \n",
    "            # Execute PRAGMA command to get column info\n",
    "            columns = cong_cur.execute(f\"PRAGMA table_info({table_name});\").fetchall()\n",
    "            \n",
    "            if not columns:\n",
    "                print(f\"No columns found in table '{table_name}'.\")\n",
    "            else:\n",
    "                for column in columns:\n",
    "                    print(f\" - {column[1]} (Type: {column[2]})\")  # Column name and type\n",
    "\n",
    "except sqlite3.Error as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "finally:\n",
    "    # Close the database connection\n",
    "    cong_db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample tweets data:\n",
      "[b'\"Brooks Joins Alabama Delegation in Voting Against Flawed Funding Bill\" http://t.co/3CwjIWYsNq', 'Republican']\n",
      "[b'\"Brooks: Senate Democrats Allowing President to Give Americans\\xe2\\x80\\x99 Jobs to Illegals\" #securetheborder https://t.co/mZtEaX8xS6', 'Republican']\n",
      "[b'\"NASA on the Square\" event this Sat. 11AM \\xe2\\x80\\x93 4PM. Stop by &amp; hear about the incredible work done in #AL05! @DowntownHSV http://t.co/R9zY8WMEpA', 'Republican']\n",
      "[b'\"The trouble with Socialism is that eventually you run out of other people\\'s money.\" - Margaret Thatcher https://t.co/X97g7wzQwJ', 'Republican']\n",
      "[b'\"The trouble with socialism is eventually you run out of other people\\'s money\" \\xe2\\x80\\x93 Thatcher. She\\'ll be sorely missed. http://t.co/Z8gBnDQUh8', 'Republican']\n"
     ]
    }
   ],
   "source": [
    "# Initialize tweet_data list\n",
    "tweet_data = []\n",
    "\n",
    "# Fill up tweet_data with sublists (tweet text, party)\n",
    "for candidate, party, tweet_text in results:\n",
    "    tweet_data.append([tweet_text, party])\n",
    "\n",
    "# Optionally print the first few entries to verify\n",
    "print(\"Sample tweets data:\")\n",
    "for tweet in tweet_data[:5]:  # Display first 5 tweets\n",
    "    print(tweet)\n",
    "\n",
    "# Close the database connection\n",
    "cong_db.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20201014)\n",
    "\n",
    "tweet_data_sample = random.choices(tweet_data,k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's our (cleaned) tweet: b'Earlier today, I spoke on the House Floor abt protecting health care for women and praised @PPmarmonte for their work on the Central Coast. https://t.co/WqgTRzT7VV'\n",
      "Actual party is Democratic and our classifier says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: b'Go Tribe! #RallyTogether https://t.co/0NXutFL9L5'\n",
      "Actual party is Democratic and our classifier says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: b\"Apparently, Trump thinks it's just too easy for students overwhelmed by the crushing burden of debt to pay off student loans #TrumpBudget https://t.co/ckYQO5T0Qh\"\n",
      "Actual party is Democratic and our classifier says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: b'We\\xe2\\x80\\x99re grateful for our first responders, our rescue personnel, our firefighters, our police, and volunteers who have been working tirelessly to keep people safe, provide much-needed help, while putting their own lives on the line.\\n\\nhttps://t.co/eZPv0vMIz3'\n",
      "Actual party is Republican and our classifier says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: b'Let\\xe2\\x80\\x99s make it even Greater !! #KAG \\xf0\\x9f\\x87\\xba\\xf0\\x9f\\x87\\xb8 https://t.co/y9qoZD5L2z'\n",
      "Actual party is Republican and our classifier says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: b\"We have about 1hr until the @cavs tie up the series 2-2. I'm #ALLin216 @RepBarbaraLee you scared? #roadtovictory\"\n",
      "Actual party is Democratic and our classifier says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: b'Congrats to @belliottsd on his new gig at SD City Hall. We are glad you will continue to serve\\xe2\\x80\\xa6 https://t.co/fkvMw3cqdI'\n",
      "Actual party is Democratic and our classifier says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: b'We are really close, we have over $3500 raised toward the match right now. Whoot!! (That\\xe2\\x80\\x99s $7000 for the non-math majors in the room \\xf0\\x9f\\x98\\x82). Help us get there https://t.co/Tu34C472sD https://t.co/QsdQkYpsmC'\n",
      "Actual party is Democratic and our classifier says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: b'Today, the comment period for @POTUS\\xe2\\x80\\x99s plan to expand offshore drilling opened to the public. You have 60 days (until March 9) to share why you oppose the proposed program directly with the Trump Administration. Comments can be made by email or mail. https://t.co/BaaYMeJxQn'\n",
      "Actual party is Democratic and our classifier says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: b'Celebrated @ICSEastLA\\xe2\\x80\\x99s 22 years of Eastside commitment &amp; saluted community leaders at last night\\xe2\\x80\\x99s awards dinner! https://t.co/7V7gH8giVB'\n",
      "Actual party is Democratic and our classifier says Democratic.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop through the sampled tweets and estimate the party\n",
    "for tweet, party in tweet_data_sample:\n",
    "    # Clean and prepare the tweet for classification\n",
    "    cleaned_tweet = tweet.lower()  # Lowercase the tweet\n",
    "    features = conv_features(cleaned_tweet, feature_words)  # Extract features using your conv_features function\n",
    "    \n",
    "    # Estimate the party using the classifier\n",
    "    estimated_party = classifier.classify(features)  # Use the classifier to predict the party\n",
    "    \n",
    "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
    "    print(f\"Actual party is {party} and our classifier says {estimated_party}.\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at it some, let's score a bunch and see how we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary:\n",
      "Republican: {'Democratic': 4343}\n",
      "Democratic: {'Democratic': 5658}\n"
     ]
    }
   ],
   "source": [
    "# Dictionary of counts by actual party and estimated party\n",
    "parties = ['Republican', 'Democratic']\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "# Number of tweets to score\n",
    "num_to_score = 10000\n",
    "random.shuffle(tweet_data)\n",
    "\n",
    "# Loop through tweet data and estimate parties\n",
    "for idx, tp in enumerate(tweet_data):\n",
    "    tweet, party = tp\n",
    "\n",
    "    # Clean and prepare the tweet for classification\n",
    "    cleaned_tweet = tweet.lower()  # Lowercase the tweet\n",
    "    features = conv_features(cleaned_tweet, feature_words)  # Extract features\n",
    "\n",
    "    # Estimate the party using the classifier\n",
    "    estimated_party = classifier.classify(features)  # Predict the party\n",
    "    \n",
    "    # Store the results\n",
    "    results[party][estimated_party] += 1\n",
    "\n",
    "    # Break after scoring a certain number of tweets\n",
    "    if idx >= num_to_score:\n",
    "        break\n",
    "\n",
    "# Display the results summary\n",
    "print(\"Results summary:\")\n",
    "for actual_party, estimated in results.items():\n",
    "    print(f\"{actual_party}: {dict(estimated)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 56.82%\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "for actual_party in results.keys():\n",
    "    correct_predictions += results[actual_party][actual_party]  # Count correctly classified tweets\n",
    "    total_predictions += sum(results[actual_party].values())  # Count total predictions for this actual party\n",
    "\n",
    "# Calculate and print accuracy\n",
    "accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "print(f\"Accuracy: {accuracy:.2%}\")  # Print accuracy as a percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "\n",
    "The summary above suggests that the classifier is misclassifying the tweets from the Republican party incorrectly. There are 4343 tweets of the 10,000 that have been tested that are wrongfully classified as Democratic. In contrast, the model is performing pretty well in classifying Democratic tweets; classifying 5658 tweets correctly. \n",
    "\n",
    "These values suggest that the classifier may be trained on unbalanced data and data biased towards the Democratic party language. To improve the overall performance of the classifier, it would be beneficial to diversify the Republican party tweets or introduce more data that would classify as the Republican party. The Naive Bayes classifier needs to be trained on more Republican party instances. This also presents the opportunity to rebalance the data that the Naive Bayes classifier is trained on."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
